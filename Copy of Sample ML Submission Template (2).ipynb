{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"10B2s5af8INkHgIz_7XBjW3iNDbGY7ltx","timestamp":1685302783190}],"collapsed_sections":["vncDsAP0Gaoa","FJNUwmbgGyua","w6K7xa23Elo4","yQaldy8SH6Dl","mDgbUHAGgjLW","O_i_v8NEhb9l","HhfV-JJviCcP","Y3lxredqlCYt","3RnN4peoiCZX","x71ZqKXriCWQ","7hBIi_osiCS2","JlHwYmJAmNHm","35m5QtbWiB9F","PoPl-ycgm1ru","H0kj-8xxnORC","nA9Y7ga8ng1Z","PBTbrJXOngz2","u3PMJOP6ngxN","dauF4eBmngu3","bKJF3rekwFvQ","MSa1f5Uengrz","GF8Ens_Soomf","0wOQAZs5pc--","K5QZ13OEpz2H","lQ7QKXXCp7Bj","448CDAPjqfQr","KSlN3yHqYklG","t6dVpIINYklI","ijmpgYnKYklI","-JiQyfWJYklI","EM7whBJCYoAo","fge-S5ZAYoAp","85gYPyotYoAp","RoGjAbkUYoAp","4Of9eVA-YrdM","iky9q4vBYrdO","F6T5p64dYrdO","y-Ehk30pYrdP","bamQiAODYuh1","QHF8YVU7Yuh3","GwzvFGzlYuh3","qYpmQ266Yuh3","OH-pJp9IphqM","bbFf2-_FphqN","_ouA3fa0phqN","Seke61FWphqN","PIIx-8_IphqN","t27r6nlMphqO","r2jJGEOYphqO","b0JNsNcRphqO","BZR9WyysphqO","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","YJ55k-q6phqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","NC_X3p0fY2L0","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","g-ATYxFrGrvw","Yfr_Vlr8HBkt","8yEUt7NnHlrM","tEA2Xm5dHt1r","I79__PHVH19G","Ou-I18pAyIpj","fF3858GYyt-u","4_0_7-oCpUZd","hwyV_J3ipUZe","3yB-zSqbpUZe","dEUvejAfpUZe","Fd15vwWVpUZf","bn_IUdTipZyH","49K5P_iCpZyH","Nff-vKELpZyI","kLW572S8pZyI","dWbDXHzopZyI","yLjJCtPM0KBk","xiyOF9F70UgQ","7wuGOrhz0itI","id1riN9m0vUs","578E2V7j08f6","89xtkJwZ18nB","67NQN5KX2AMe","Iwf50b-R2tYG","GMQiZwjn3iu7","WVIkgGqN3qsr","XkPnILGE3zoT","Hlsf0x5436Go","mT9DMSJo4nBL","c49ITxTc407N","OeJFEK0N496M","9ExmJH0g5HBk","cJNqERVU536h","k5UmGsbsOxih","T0VqWOYE6DLQ","qBMux9mC6MCf","-oLEiFgy-5Pf","C74aWNz2AliB","2DejudWSA-a0","pEMng2IbBLp7","rAdphbQ9Bhjc","TNVZ9zx19K6k","nqoHp30x9hH9","rMDnDkt2B6du","yiiVWRdJDDil","1UUpS68QDMuG","kexQrXU-DjzY","T5CmagL3EC8N","BhH2vgX9EjGr","qjKvONjwE8ra","P1XJ9OREExlT","VFOzZv6IFROw","TIqpNgepFxVj","VfCC591jGiD4","OB4l2ZhMeS1U","ArJBuiUVfxKd","4qY1EAkEfxKe","PiV4Ypx8fxKe","TfvqoZmBfxKf","dJ2tPlVmpsJ0","JWYfwnehpsJ1","-jK_YjpMpsJ2","HAih1iBOpsJ2","zVGeBEFhpsJ2","bmKjuQ-FpsJ3","Fze-IPXLpx6K","7AN1z2sKpx6M","9PIHJqyupx6M","_-qAgymDpx6N","Z-hykwinpx6N","h_CCil-SKHpo","cBFFvTBNJzUa","HvGl1hHyA_VK","EyNgTHvd2WFk","KH5McJBi2d8v","iW_Lq9qf2h6X","-Kee-DAl2viO","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    - BIKE SHARING DEMAND PREDICTION\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - Regression\n","##### **Contribution**    - Individual\n","##### **Team Member 1 -**D G V S PRADEEP\n"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["**Business problem:** At present Rental bicycles are presented in numerous metropolitan urban communities for the improvement of portability solace. It is critical to make the rental bicycle accessible and open to general society brilliantly as it reduces the holding up time. Ultimately, giving the city a steady stockpile of rental bicycles turns into a main issue. The significant part is the expectation of bicycle count expected at every hour for the steady stockpile of rental bicycles.  \n","\n","\n","First we import the essential libraries and check out at our information and its qualities. We have a dataset of 8760 lines and 14 sections with no copy/missing information. Next we concentrate on the highlights completely and the information it addresses.\n","\n","\n","In information fighting, we first see that the segment 'Date' is in 'object' datatype, and we convert it to datetime datatype. Later from the date section, we extricate, 'day_of_week', 'month' and 'year' (year as a clear cut esteem) We drop the date segment and we rename sections for convinence. We convert 'hour' section to 'protest' datatype as it ought to be considered as a clear cut esteem.\n","\n","\n","Later we imagine our information and perform univariate investigation, bivariate examination concerning the dependant variable. The experiences found from each graph is depicted. The straight connection between the mathematical highlights and dependant variable is likewise plotted. At last, we envision the connection heatmap and pairplot for better comprehension.\n","\n","\n","In view of our representations, we plan 3 speculative articulations and perform theory tests. The assertions are:\n","\n","The typical bicycle include in Seoul city anytime of time is more noteworthy than 100.\n","\n","The typical temperature in Seoul city anytime is grater than 10 degree Celsius.\n","The Standard deviation of humdidity in Seoul city is 20.\n","This moment was the opportunity for highlight designing. We took care of the exceptions in 'Wind speed' segment by utilizing the covering technique. In light of the relationship heatmap, we had the segments 'dew point temperature' and 'Temperature' were exceptionally corresponded. So we dropped the 'dew point temperature' segment. In the Times of week segment, we obsereved from this section that the example of work days and ends of the week is unique, in the end of the week the interest turns out to be high in the early evening. While the interest for office timings is high during non-weekend days, we can additionally change this section to non-weekend days and ends of the week. Furthur, we performed one hot encoding on our clear cut highlights with dropping the principal section being valid. We found out during representation that our dependant variable, 'Rented_bike_count' was correct slanted, consequently to beat this we applied a squareroot change to get an ordinary dispersion. Next we scaled our information utilizing MinMax scaler. At long last we split our information into train and test in 80-20 proportion.\n","\n","The information was prepared to squeeze into an AI model. In the first place, we utilized Straight Relapse. We got changed r2 score as 76.65%. There was no hyperparameter to be tuned. Second, we utilized Ridge(L2) Relapse. We got changed r2 score as 76.65%. We involved GridSearchCV for hyperparameter tuning in which we saw a slight improvement. Third, We utilized Lasso(L1) Relapse with GridSearchCV for hyperparameter tuning. We got changed r2 score as 76.65%. Our fouth calculation was Irregular Backwoods Regressor. With GridSearchCV for setting our hyperparameters, we got changed r2 score as 91%.\n","\n","So at long last, the bicycle rental organization can convey an AI model that utilizes Irregular Timberland Regressor to foresee the interest for city bicycles for a specific hour, which can assist the organization with satisfying the need precisely. Going against the norm when the organization predicts to be a low interest day/season, the bicycles can be shipped off maintainance."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["Provide your GitHub Link here."],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["***BUSINESS PROBLEM OVERVIEW ***\n","\n","Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes..**"],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required. \n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Libraries\n","# Numpy and Pandas\n","import numpy as np\n","import pandas as pd\n","\n","# Visualization tools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Libraries for hypothesis testing\n","from scipy.stats import uniform\n","from scipy.stats import norm\n","from scipy.stats import chi2\n","from scipy.stats import t\n","from scipy.stats import f\n","\n","# Libraries for data pre-processing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import GridSearchCV\n","\n","# Libraries for model implementation\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Lasso\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import ElasticNet\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# Libraries for model metrics\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.model_selection import cross_val_score"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"wC6In99LWqcm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["# Load Dataset\n","df = pd.read_csv('/content/drive/MyDrive/ALMA PROJECT DATA/SeoulBikeData.csv', encoding='unicode_escape')"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","df.head()"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","df.shape"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","print(len(df[df.duplicated()]))"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","df.isna().sum()"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the missing values"],"metadata":{"id":"3q5wnI3om9sJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["The above dataset provides us the data on number of bikes that were rented in Seoul city by the hour of the day. The corresponding weather data for the hour is also given.\n","\n","The dataset contains 8760 entries with 14 features. 4 out of 14 columns have 'object' data type, the rest are numeric.\n","\n","There are no missing values/duplicate values in the dataset."],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","df.columns"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","df.describe()"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables Description "],"metadata":{"id":"PBTbrJXOngz2"}},{"cell_type":"markdown","source":["1.Date: Date of the day.\n","\n","2.Rented Bike Count: The number of bikes the were rented.\n","\n","3.Hour: Hour of the day.\n","\n","4.Temperature(°C): Temperature of the hour in degree Celsius.\n","\n","5.Humidity(%): Humidity of the hour in %.\n","\n","6.Wind speed (m/s): Wind speed during the hour in metre/second.\n","\n","7.Visibility (10m): Visibility of 10 metres.\n","\n","8.Dew point temperature(°C): Dew point temperature in that hour in °C.\n","\n","9.Solar Radiation (MJ/m2): Solar radidation in MegaJoules / metre2.\n","\n","10.Rainfall(mm): Rainfall in mellimeter.\n","\n","11.Snowfall (cm): Snowfall in centimeter.\n","\n","12.Seasons: The current season.\n","\n","13.Holiday: Whether the given day is a holiday.\n","\n","14.Functioning Day: Whether the given day is a Functioning Day.\n"],"metadata":{"id":"aJV4KIxSnxay"}},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","df.nunique()"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ***Data Wrangling***"],"metadata":{"id":"dauF4eBmngu3"}},{"cell_type":"markdown","source":["### Data Wrangling Code"],"metadata":{"id":"bKJF3rekwFvQ"}},{"cell_type":"code","source":["# Write your code to make your dataset analysis ready.\n","\n","# Copying the dataset for backup\n","df_copy = df.copy()\n","\n","# converting date column dtype object to date \n","df['Date']=pd.to_datetime(df['Date'])\n","\n","# split day of week, month and year in three column\n","df['day_of_week'] = df['Date'].dt.day_name() # extract week name from Date column\n","df[\"month\"] = df['Date'].dt.month_name() # extract month name from Date column\n","df[\"year\"] = df['Date'].map(lambda x: x.year).astype(\"object\") # extract year from Date column and convert it in object type \n","\n","# drop the Date column\n","df.drop(columns=['Date'],inplace=True)\n","\n","# Renaming columns for convinence \n","df=df.rename(columns={'Rented Bike Count':'Rented_Bike_Count','Temperature(°C)':'Temperature','Humidity(%)':'Humidity',\n","                      'Wind speed (m/s)':'Wind_speed','Visibility (10m)':'Visibility','Dew point temperature(°C)':'Dew_point_temperature',\n","                      'Solar Radiation (MJ/m2)':'Solar_Radiation','Rainfall(mm)':'Rainfall',\n","                      'Snowfall (cm)':'Snowfall','Functioning Day':'Functioning_Day'})\n","\n","# convert Hour column integer to Categorical \n","df['Hour']=df['Hour'].astype('object')"],"metadata":{"id":"wk-9a2fpoLcV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"sfv0kDIGaxZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Divide Data in categorical and numerical features\n","numeric_features= df.select_dtypes(exclude='object')\n","categorical_features=df.select_dtypes(include='object')"],"metadata":{"id":"CJEeoyumaxlD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numeric_features.head()"],"metadata":{"id":"7aQostPGa3fo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What all manipulations have you done and insights you found?"],"metadata":{"id":"MSa1f5Uengrz"}},{"cell_type":"markdown","source":["1.First we create a backup dataset under the name 'df_copy'.\n","\n","2.The column 'Date' is in 'object' datatype, we need to convert it to datetime datatype.\n","\n","3.From the date column, we extract, 'day_of_week', 'month' & 'year' (year as a categorical value)\n","\n","4.We drop the date column\n","\n","5.We rename columns for convinence\n","\n","6.We convert 'hour' column to 'object' datatype.It should be considered as a categorical value."],"metadata":{"id":"LbyXE7I1olp8"}},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"code","source":["# Example usage of sns.set()\n","sns.set(rc={'figure.figsize': (10, 6)})"],"metadata":{"id":"oIKwJ80HbNeI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.set_style(style='white')"],"metadata":{"id":"sCT2lCmTbN0L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 1"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["# Chart - 1 visualization code\n","sns.histplot(df['Rented_Bike_Count'],kde=True,color='darkslateblue')\n","plt.axvline(df['Rented_Bike_Count'].mean(), color='g', linestyle='dashed', linewidth=2)\n","plt.axvline(df['Rented_Bike_Count'].median(), color='red', linestyle='dashed', linewidth=2)"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"K5QZ13OEpz2H"}},{"cell_type":"markdown","source":["Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness."],"metadata":{"id":"XESiWehPqBRc"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"lQ7QKXXCp7Bj"}},{"cell_type":"markdown","source":["The data is right skewed."],"metadata":{"id":"C_j1G7yiqdRP"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"448CDAPjqfQr"}},{"cell_type":"markdown","source":["As more number of bikes are less than 500, the mass reorganization of the bikes will be easier for the company, thus giving a positive business impact."],"metadata":{"id":"3cspy4FjqxJW"}},{"cell_type":"markdown","source":["#### Chart - 2"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","# Histogram plot with KDE\n","sns.histplot(df['Temperature'], kde=True, color='darkslateblue')\n","plt.axvline(df['Temperature'].mean(), color='g', linestyle='dashed', linewidth=2)\n","plt.axvline(df['Temperature'].median(), color='red', linestyle='dashed', linewidth=2)\n","\n","# Show the plot\n","plt.show()\n"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t6dVpIINYklI"}},{"cell_type":"markdown","source":["Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness."],"metadata":{"id":"5aaW0BYyYklI"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ijmpgYnKYklI"}},{"cell_type":"markdown","source":["The mean & median values are very close. The data is slightly left skewed."],"metadata":{"id":"PSx9atu2YklI"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"-JiQyfWJYklI"}},{"cell_type":"markdown","source":["The mean & median temperature lies around 12-15 degrees, thus making it a pleasant temperature for the people to choose bikes, thus leading a positive business impact."],"metadata":{"id":"BcBbebzrYklV"}},{"cell_type":"markdown","source":["#### Chart - 3"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","sns.histplot(df['Humidity'],kde=True,color='darkslateblue')\n","plt.axvline(df['Humidity'].mean(), color='g', linestyle='dashed', linewidth=2)\n","plt.axvline(df['Humidity'].median(), color='red', linestyle='dashed', linewidth=2)"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"fge-S5ZAYoAp"}},{"cell_type":"markdown","source":["Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness."],"metadata":{"id":"5dBItgRVYoAp"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"85gYPyotYoAp"}},{"cell_type":"markdown","source":["We can see a close normal distribution curve. The mean & median lies close to 56%."],"metadata":{"id":"4jstXR6OYoAp"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"RoGjAbkUYoAp"}},{"cell_type":"markdown","source":["When we have humdidty close to 55-60%, people are more likely to choose bikesover cars as the need of water consumption for an individual is reduced."],"metadata":{"id":"zfJ8IqMcYoAp"}},{"cell_type":"markdown","source":["#### Chart - 4"],"metadata":{"id":"4Of9eVA-YrdM"}},{"cell_type":"code","source":["# Chart - 4 visualization code\n","sns.histplot(df['Wind_speed'],kde=True,color='darkslateblue')\n","plt.axvline(df['Wind_speed'].mean(), color='g', linestyle='dashed', linewidth=2)\n","plt.axvline(df['Wind_speed'].median(), color='red', linestyle='dashed', linewidth=2)\n"],"metadata":{"id":"irlUoxc8YrdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"iky9q4vBYrdO"}},{"cell_type":"markdown","source":["Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness."],"metadata":{"id":"aJRCwT6DYrdO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"F6T5p64dYrdO"}},{"cell_type":"markdown","source":["The wind speed data is right skewed with an average speed of 1.8 m/s."],"metadata":{"id":"Xx8WAJvtYrdO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"y-Ehk30pYrdP"}},{"cell_type":"markdown","source":["Wind speed generally would have no impact of ridership, but when wind speeds go higher than average, the ridership may tank."],"metadata":{"id":"jLNxxz7MYrdP"}},{"cell_type":"markdown","source":["#### Chart - 5"],"metadata":{"id":"bamQiAODYuh1"}},{"cell_type":"code","source":["# Chart - 5 visualization code\n","sns.histplot(df['Visibility'],kde=True,color='darkslateblue')\n","plt.axvline(df['Visibility'].mean(), color='g', linestyle='dashed', linewidth=2)\n","plt.axvline(df['Visibility'].median(), color='red', linestyle='dashed', linewidth=2)"],"metadata":{"id":"TIJwrbroYuh3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"QHF8YVU7Yuh3"}},{"cell_type":"markdown","source":["Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness."],"metadata":{"id":"dcxuIMRPYuh3"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"GwzvFGzlYuh3"}},{"cell_type":"markdown","source":["Visibility has a highly left skewed data indicating the visibility as clear for most days."],"metadata":{"id":"uyqkiB8YYuh3"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"qYpmQ266Yuh3"}},{"cell_type":"markdown","source":["Generally, good visibility a basic must-have."],"metadata":{"id":"_WtzZ_hCYuh4"}},{"cell_type":"markdown","source":["#### Chart - 6"],"metadata":{"id":"OH-pJp9IphqM"}},{"cell_type":"code","source":["# Chart - 6 visualization code\n","sns.histplot(df['Dew_point_temperature'],kde=True,color='darkslateblue')\n","plt.axvline(df['Dew_point_temperature'].mean(), color='g', linestyle='dashed', linewidth=2)\n","plt.axvline(df['Dew_point_temperature'].median(), color='red', linestyle='dashed', linewidth=2)"],"metadata":{"id":"kuRf4wtuphqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"bbFf2-_FphqN"}},{"cell_type":"markdown","source":["Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness."],"metadata":{"id":"loh7H2nzphqN"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"_ouA3fa0phqN"}},{"cell_type":"markdown","source":["The dew point temperature is slightly left skewed."],"metadata":{"id":"VECbqPI7phqN"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"Seke61FWphqN"}},{"cell_type":"markdown","source":["No"],"metadata":{"id":"DW4_bGpfphqN"}},{"cell_type":"markdown","source":["#### Chart - 7"],"metadata":{"id":"PIIx-8_IphqN"}},{"cell_type":"code","source":["# Chart - 7 visualization code\n","sns.histplot(df['Solar_Radiation'],kde=True,color='darkslateblue')\n","plt.axvline(df['Solar_Radiation'].mean(), color='g', linestyle='dashed', linewidth=2)\n","plt.axvline(df['Solar_Radiation'].median(), color='red', linestyle='dashed', linewidth=2)"],"metadata":{"id":"lqAIGUfyphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t27r6nlMphqO"}},{"cell_type":"markdown","source":["Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness."],"metadata":{"id":"iv6ro40sphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"r2jJGEOYphqO"}},{"cell_type":"markdown","source":["It is highly right skewed."],"metadata":{"id":"Po6ZPi4hphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"b0JNsNcRphqO"}},{"cell_type":"markdown","source":["NO"],"metadata":{"id":"xvSq8iUTphqO"}},{"cell_type":"markdown","source":["#### Chart - 8"],"metadata":{"id":"BZR9WyysphqO"}},{"cell_type":"code","source":["# Chart - 8 visualization code\n","sns.histplot(df['Snowfall'],kde=True,color='darkslateblue')\n","plt.axvline(df['Snowfall'].mean(), color='g', linestyle='dashed', linewidth=2)\n","plt.axvline(df['Snowfall'].median(), color='red', linestyle='dashed', linewidth=2)"],"metadata":{"id":"TdPTWpAVphqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"jj7wYXLtphqO"}},{"cell_type":"markdown","source":["Histogram along with the KDE line lets us visualize the density & the distribution of the feature. The mean & medain dashed lines also gives us the level of skewness."],"metadata":{"id":"Ob8u6rCTphqO"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"eZrbJ2SmphqO"}},{"cell_type":"markdown","source":["As the mean & median is close to 0, most days there's no snowfall."],"metadata":{"id":"mZtgC_hjphqO"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"rFu4xreNphqO"}},{"cell_type":"markdown","source":["The snowfall days might negatively impact the business."],"metadata":{"id":"ey_0qi68phqO"}},{"cell_type":"markdown","source":["#### Chart - 9"],"metadata":{"id":"YJ55k-q6phqO"}},{"cell_type":"code","source":["# Chart - 9 visualization code\n","plt.pie(df['Seasons'].value_counts(),labels = df['Seasons'].value_counts().keys().tolist(),autopct='%.0f%%')\n","plt.title('Seasons')\n","plt.show()"],"metadata":{"id":"B2aS4O1ophqO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"gCFgpxoyphqP"}},{"cell_type":"markdown","source":["Pie charts are one of the best ways for univariate analysis of categorical data."],"metadata":{"id":"TVxDimi2phqP"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"OVtJsKN_phqQ"}},{"cell_type":"markdown","source":["There's even distribution suggesting that we have year round data."],"metadata":{"id":"ngGi97qjphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"lssrdh5qphqQ"}},{"cell_type":"markdown","source":["NO"],"metadata":{"id":"tBpY5ekJphqQ"}},{"cell_type":"markdown","source":["#### Chart - 10"],"metadata":{"id":"U2RJ9gkRphqQ"}},{"cell_type":"code","source":["# Chart - 10 visualization code\n","plt.pie(df['Holiday'].value_counts(),labels = df['Holiday'].value_counts().keys().tolist(),autopct='%.0f%%')\n","plt.title('Holiday')\n","plt.show()"],"metadata":{"id":"GM7a4YP4phqQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"1M8mcRywphqQ"}},{"cell_type":"markdown","source":["Pie charts are one of the best ways for univariate analysis of categorical data."],"metadata":{"id":"8agQvks0phqQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"tgIPom80phqQ"}},{"cell_type":"markdown","source":["Most of the data we have is on a 'no holiday' day."],"metadata":{"id":"Qp13pnNzphqQ"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"JMzcOPDDphqR"}},{"cell_type":"markdown","source":["Many people ride thier bikes to work/school, thus this feature may have positive impact on the business"],"metadata":{"id":"R4Ka1PC2phqR"}},{"cell_type":"markdown","source":["#### Chart - 11"],"metadata":{"id":"x-EpHcCOp1ci"}},{"cell_type":"code","source":["# Chart - 11 visualization code\n","plt.pie(df['Functioning_Day'].value_counts(),labels = df['Functioning_Day'].value_counts().keys().tolist(),autopct='%.0f%%')\n","plt.title('Functioning_Day')\n","plt.show()"],"metadata":{"id":"mAQTIvtqp1cj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"X_VqEhTip1ck"}},{"cell_type":"markdown","source":["Pie charts are one of the best ways for univariate analysis of categorical data."],"metadata":{"id":"-vsMzt_np1ck"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"8zGJKyg5p1ck"}},{"cell_type":"markdown","source":["Most of the data we have is on a 'functioning' day."],"metadata":{"id":"ZYdMsrqVp1ck"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"PVzmfK_Ep1ck"}},{"cell_type":"markdown","source":["As we have more data on a functioning day, it lets us dig deep into the insights we can get from the hour of the day."],"metadata":{"id":"druuKYZpp1ck"}},{"cell_type":"markdown","source":["#### Chart - 12"],"metadata":{"id":"n3dbpmDWp1ck"}},{"cell_type":"code","source":["# Chart - 12 visualization code\n","sns.barplot(data=df,x='Seasons',y='Rented_Bike_Count',palette='mako')"],"metadata":{"id":"bwevp1tKp1ck"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"ylSl6qgtp1ck"}},{"cell_type":"markdown","source":["A barplot is an effective way to establish relationship between a numerical feature and a categorical feature."],"metadata":{"id":"m2xqNkiQp1ck"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ZWILFDl5p1ck"}},{"cell_type":"markdown","source":["The bike ridership is significantly less in winter compared to the other 3 seasons."],"metadata":{"id":"x-lUsV2mp1ck"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"M7G43BXep1ck"}},{"cell_type":"markdown","source":["The company needs more bike circulated in summer, autumn & spring & while in winter, they can schedule maintainance."],"metadata":{"id":"5wwDJXsLp1cl"}},{"cell_type":"markdown","source":["#### Chart - 13"],"metadata":{"id":"Ag9LCva-p1cl"}},{"cell_type":"code","source":["# Chart - 13 visualization code\n","\n","sns.barplot(data=df,x='Hour',y='Rented_Bike_Count',palette='mako')"],"metadata":{"id":"EUfxeq9-p1cl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"E6MkPsBcp1cl"}},{"cell_type":"markdown","source":["A barplot is an effective way to establish relationship between a numerical feature and a categorical feature."],"metadata":{"id":"V22bRsFWp1cl"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"2cELzS2fp1cl"}},{"cell_type":"markdown","source":["The ridership sees demand in the rush hours & does'nt suddenly drop but see steady demand till 12:00 am."],"metadata":{"id":"ozQPc2_Ip1cl"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact? \n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"3MPXvC8up1cl"}},{"cell_type":"markdown","source":["Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"GL8l1tdLp1cl"}},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"g2h0hHmMbkq0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Chart - 14 - Correlation Heatmap"],"metadata":{"id":"NC_X3p0fY2L0"}},{"cell_type":"code","source":["# Correlation Heatmap visualization code\n","plt.figure(figsize=(20,10))\n","sns.heatmap(df.corr(),annot=True,cmap=\"crest\")\n","plt.show()"],"metadata":{"id":"xyC9zolEZNRQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"UV0SzAkaZNRQ"}},{"cell_type":"markdown","source":["Correlation plots are used to understand which variables are related to each other and the strength of this relationship."],"metadata":{"id":"DVPuT8LYZNRQ"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"YPEH6qLeZNRQ"}},{"cell_type":"markdown","source":["Humidity has low correlation with visibility due to solar radiation.\n","\n","Dew point temperature and temperature are highly related."],"metadata":{"id":"bfSqtnDqZNRR"}},{"cell_type":"markdown","source":["#### Chart - 15 - Pair Plot "],"metadata":{"id":"q29F0dvdveiT"}},{"cell_type":"code","source":["# Pair Plot visualization code\n","sns.pairplot(df, corner=True)"],"metadata":{"id":"o58-TEIhveiU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"EXh0U9oCveiU"}},{"cell_type":"markdown","source":["A pair plot is a type of visualization that shows pairwise relationships between variables in a dataset"],"metadata":{"id":"eMmPjTByveiU"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"22aHeOlLveiV"}},{"cell_type":"markdown","source":["A pair plot is a visualization that shows pairwise relationships between variables in a dataset. It plots scatter plots for each pair of variables and histograms for each variable on the diagonal."],"metadata":{"id":"uPQ8RGwHveiV"}},{"cell_type":"markdown","source":["## ***5. Hypothesis Testing***"],"metadata":{"id":"g-ATYxFrGrvw"}},{"cell_type":"markdown","source":["### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."],"metadata":{"id":"Yfr_Vlr8HBkt"}},{"cell_type":"markdown","source":["1.The average bike count in Seoul city at any point of time is greater than 100.\n","\n","2.The average temperature in Seoul city at any point is greater than 10 degree Celsius.\n","\n","3.The Standard deviation of humdidity in Seoul city is 20."],"metadata":{"id":"-7MS06SUHkB-"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 1"],"metadata":{"id":"8yEUt7NnHlrM"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"tEA2Xm5dHt1r"}},{"cell_type":"markdown","source":["Research hypothesis: The average bike count in Seoul city at any point of time is greater than 100.\n","\n","*   Null hypothesis H0: Average = 100.\n","*   Alternate hypothesis Ha: Average > 100.\n","\n"],"metadata":{"id":"HI9ZP0laH0D-"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"I79__PHVH19G"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","# Perform Statistical Test to obtain P-Value\n","\n","import pandas as pd\n","import numpy as np\n","\n","# Loading the dataset\n","df = pd.read_csv('/content/drive/MyDrive/ALMA PROJECT DATA/SeoulBikeData.csv', encoding='unicode_escape')\n","\n","# Sample 500 data points from the 'Rented Bike Count' column\n","rented_bike_count_sample = df['Rented Bike Count'].sample(500)\n","\n","# Calculate the mean and standard deviation\n","rented_bike_count_mean = np.mean(rented_bike_count_sample)\n","rented_bike_count_std = np.std(rented_bike_count_sample)\n","\n","# Print the results\n","print('Mean:', rented_bike_count_mean)\n","print('Standard Deviation:', rented_bike_count_std)\n"],"metadata":{"id":"oZrfquKtyian"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Computing test statistic\n","\n","ts = (rented_bike_count_mean-100)/(rented_bike_count_std/(np.sqrt(500)))\n","ts"],"metadata":{"id":"MvhwEgyKi4bE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"Ou-I18pAyIpj"}},{"cell_type":"markdown","source":["We have chosen Z-test to obtain p-value."],"metadata":{"id":"s2U0kk00ygSB"}},{"cell_type":"code","source":["# Calculating the probability\n","prob_z = norm.cdf(9.3441, 0, 1)\n","print(prob_z)"],"metadata":{"id":"uFFAdqb7i4s0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# P-Value\n","p1 = 1-prob_z\n","p1"],"metadata":{"id":"Q8s3ngGejHrM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"fF3858GYyt-u"}},{"cell_type":"markdown","source":["As we are performing hypothesis testing for mean, we have chosen Z-test to obtain p-value. The probability we have obtained is close to 100%, so we have sufficient evidence to reject H0. Therefore, the average bike count in Seoul city at any point of time is greater than 100."],"metadata":{"id":"HO4K0gP5y3B4"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 2"],"metadata":{"id":"4_0_7-oCpUZd"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"hwyV_J3ipUZe"}},{"cell_type":"markdown","source":["\n","The average temperature in Seoul city at any point is grater than 10 degree Celsius.\n","\n","\n","\n","*   Null hypothesis H0: Average = 10.\n","*   Alternate hypothesis Ha: Average > 100.\n","\n"],"metadata":{"id":"FnpLGJ-4pUZe"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"3yB-zSqbpUZe"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","temp_sample = df['Temperature(°C)'].sample(500)\n","temp_mean = np.mean(temp_sample)\n","temp_std = np.std(temp_sample)"],"metadata":{"id":"sWxdNTXNpUZe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp_std"],"metadata":{"id":"V8mhRm7bjqaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Computing test statistic\n","\n","ts2 = (temp_mean-10)/(temp_std/(np.sqrt(500)))\n","ts2"],"metadata":{"id":"_piLQW63jtEp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating the probability\n","prob_z = norm.cdf(4.90, 0, 1)\n","print(prob_z)"],"metadata":{"id":"X3QUNImKjvtK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"dEUvejAfpUZe"}},{"cell_type":"code","source":["# P-Value\n","p1 = 1-prob_z\n","p1"],"metadata":{"id":"B2A-cmmojyxd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We have chosen Z-test to obtain p-value."],"metadata":{"id":"oLDrPz7HpUZf"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"Fd15vwWVpUZf"}},{"cell_type":"markdown","source":["As we are performing hypothesis testing for mean, we have chosen Z-test to obtain p-value. The probability we have obtained is 99%, so we have sufficient evidence to reject H0. Therefore, the average temperature in Seoul city at any point of time is greater than 10 degrees."],"metadata":{"id":"4xOGYyiBpUZf"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 3"],"metadata":{"id":"bn_IUdTipZyH"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"49K5P_iCpZyH"}},{"cell_type":"markdown","source":["The Standard deviation of humdidity in Seoul city is 20.\n","\n","\n","*   Null hypothesis H0: Standard deviaiton != 20.\n","*   Alternate hypothesis Ha: Standard deviaiton = 20.\n","\n"],"metadata":{"id":"7gWI5rT9pZyH"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"Nff-vKELpZyI"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","\n","humid_sample = df['Humidity(%)'].sample(50)\n","S2 = (np.std(humid_sample))**2"],"metadata":{"id":"s6AnJQjtpZyI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Computing test statistic\n","\n","ts3 = (49 * S2)/(20*20)\n","ts3"],"metadata":{"id":"_v9H__f4kMaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating the probability\n","prob = chi2.cdf(53.55, 49)\n","print(prob)\n"],"metadata":{"id":"PDlXvf-skMvo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"kLW572S8pZyI"}},{"cell_type":"markdown","source":["We have chosen Chi2-test to obtain p-value."],"metadata":{"id":"ytWJ8v15pZyI"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"dWbDXHzopZyI"}},{"cell_type":"markdown","source":["\n","As we are performing hypothesis testing for standard deviation, we have chosen Chi2-test to obtain p-value. The probability we have obtained is 69%, so we have sufficient evidence to reject H0. Therefore, the standard deviation of humidity is 20."],"metadata":{"id":"M99G98V6pZyI"}},{"cell_type":"markdown","source":["## ***6. Feature Engineering & Data Pre-processing***"],"metadata":{"id":"yLjJCtPM0KBk"}},{"cell_type":"markdown","source":["### 1. Handling Missing Values"],"metadata":{"id":"xiyOF9F70UgQ"}},{"cell_type":"markdown","source":["#### What all missing value imputation techniques have you used and why did you use those techniques?"],"metadata":{"id":"7wuGOrhz0itI"}},{"cell_type":"markdown","source":["There are no missing values."],"metadata":{"id":"1ixusLtI0pqI"}},{"cell_type":"markdown","source":["### 2. Handling Outliers"],"metadata":{"id":"id1riN9m0vUs"}},{"cell_type":"code","source":["# Handling Outliers & Outlier treatments\n","\n","sns.boxplot(df['Wind speed (m/s)'])"],"metadata":{"id":"M6w2CzZf04JK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Finding the IQR\n","percentile25 = df['Wind speed (m/s)'].quantile(0.25)\n","percentile75 = df['Wind speed (m/s)'].quantile(0.75)\n","iqr = percentile75 - percentile25\n","upper_limit = percentile75 + 1.5 * iqr\n","lower_limit = percentile25 - 1.5 * iqr"],"metadata":{"id":"GQJ5Zx0lkxlj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Capping\n","df['Wind speed (m/s)'] = np.where(\n","    df['Wind speed (m/s)'] > upper_limit,\n","    upper_limit,\n","    np.where(\n","        df['Wind speed (m/s)'] < lower_limit,\n","        lower_limit,\n","        df['Wind speed (m/s)']\n","    )\n",")"],"metadata":{"id":"jlPe3UeWk1AP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking for outliers\n","sns.boxplot(df['Wind speed (m/s)'])"],"metadata":{"id":"zZz5QHY1k7Te"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all outlier treatment techniques have you used and why did you use those techniques?"],"metadata":{"id":"578E2V7j08f6"}},{"cell_type":"markdown","source":["I have used 'Capping' method to treat outliers. As there are only 8760 entries in my dataset, trimming the outliers would lead to data loss."],"metadata":{"id":"uGZz5OrT1HH-"}},{"cell_type":"markdown","source":["### 3. Categorical Encoding"],"metadata":{"id":"89xtkJwZ18nB"}},{"cell_type":"code","source":["# Encode your categorical columns"],"metadata":{"id":"21JmIYMG2hEo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all categorical encoding techniques have you used & why did you use those techniques?"],"metadata":{"id":"67NQN5KX2AMe"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"UDaue5h32n_G"}},{"cell_type":"markdown","source":["### 4. Textual Data Preprocessing \n","(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"],"metadata":{"id":"Iwf50b-R2tYG"}},{"cell_type":"markdown","source":["#### 1. Expand Contraction"],"metadata":{"id":"GMQiZwjn3iu7"}},{"cell_type":"code","source":["# Expand Contraction\n","contractions = {\n","    \"I'm\": \"I am\",\n","    \"can't\": \"cannot\",\n","    \"won't\": \"will not\",\n","    # Add more contractions and their expanded forms as needed\n","}\n","\n","def expand_contractions(text):\n","    words = text.split()\n","    expanded_words = [contractions.get(word, word) for word in words]\n","    expanded_text = \" \".join(expanded_words)\n","    return expanded_text\n","\n","# Example usage\n","contracted_text = \"I'm going to the store. It won't take long.\"\n","expanded_text = expand_contractions(contracted_text)\n","print(expanded_text)\n"],"metadata":{"id":"PTouz10C3oNN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Lower Casing"],"metadata":{"id":"WVIkgGqN3qsr"}},{"cell_type":"code","source":["# Lower Casing\n","text = \"The Quick Brown Fox JUMPS Over The LAZY Dog\"\n","lowercased_text = text.lower()\n","print(lowercased_text)\n"],"metadata":{"id":"88JnJ1jN3w7j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3. Removing Punctuations"],"metadata":{"id":"XkPnILGE3zoT"}},{"cell_type":"code","source":["# Remove Punctuations\n","import string\n","\n","text = \"Hello, how are you?\"\n","no_punctuation_text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n","print(no_punctuation_text)"],"metadata":{"id":"vqbBqNaA33c0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4. Removing URLs & Removing words and digits contain digits."],"metadata":{"id":"Hlsf0x5436Go"}},{"cell_type":"code","source":["# Remove URLs & Remove words and digits contain digits\n","import re\n","\n","text = \"I found a great website at https://www.example.com. Check it out!\"\n","no_url_text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n","print(no_url_text)"],"metadata":{"id":"2sxKgKxu4Ip3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 5. Removing Stopwords & Removing White spaces"],"metadata":{"id":"mT9DMSJo4nBL"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n"],"metadata":{"id":"fiU7hA4j2cIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove Stopwords\n","import nltk\n","from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')\n","\n","text = \"This is an example sentence with some stopwords.\"\n","stop_words = set(stopwords.words('english'))\n","\n","# Tokenize the text\n","tokens = nltk.word_tokenize(text)\n","\n","# Remove stopwords\n","filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n","\n","# Join the filtered tokens back into a sentence\n","filtered_text = ' '.join(filtered_tokens)\n","\n","print(filtered_text)\n"],"metadata":{"id":"T2LSJh154s8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove White spaces\n","text = \"    This is an example    sentence with   extra spaces.   \"\n","\n","# Remove leading and trailing white spaces\n","text = text.strip()\n","\n","# Remove extra spaces within the text\n","text = ' '.join(text.split())\n","\n","print(text)"],"metadata":{"id":"EgLJGffy4vm0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 6. Rephrase Text"],"metadata":{"id":"c49ITxTc407N"}},{"cell_type":"code","source":["# Rephrase Text\n","import nltk\n","nltk.download('punkt')"],"metadata":{"id":"Nf6t8p4x2mc_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Rephrase Text\n","text = \"I found a great website at https://www.example.com. Check it out!\"\n","no_url_text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n","print(no_url_text)\n"],"metadata":{"id":"foqY80Qu48N2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove URLs from the text\n","import re\n","\n","text = \"I discovered an excellent website at https://www.example.com. Take a look!\"\n","removed_urls = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n","print(removed_urls)\n"],"metadata":{"id":"C2PZu5md2s3w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 7. Tokenization"],"metadata":{"id":"OeJFEK0N496M"}},{"cell_type":"code","source":["# Tokenization\n","import nltk\n","nltk.download('punkt')\n","\n","text = \"Tokenization is an important step in natural language processing.\"\n","tokens = nltk.word_tokenize(text)\n","\n","print(tokens)\n"],"metadata":{"id":"ijx1rUOS5CUU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 8. Text Normalization"],"metadata":{"id":"9ExmJH0g5HBk"}},{"cell_type":"code","source":["# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n","import nltk\n","from nltk.stem import PorterStemmer\n","\n","stemmer = PorterStemmer()\n","\n","word = \"running\"\n","stemmed_word = stemmer.stem(word)\n","\n","print(stemmed_word)"],"metadata":{"id":"AIJ1a-Zc5PY8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","\n","nltk.download('wordnet')\n","\n","lemmatizer = WordNetLemmatizer()\n","\n","word = \"running\"\n","lemmatized_word = lemmatizer.lemmatize(word)\n","\n","print(lemmatized_word)"],"metadata":{"id":"3Q4MkIWi21k1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which text normalization technique have you used and why?"],"metadata":{"id":"cJNqERVU536h"}},{"cell_type":"markdown","source":["The choice of text normalization techniques depends on the specific requirements of the NLP task and the characteristics of the dataset being processed. Different techniques may be more suitable for different scenarios."],"metadata":{"id":"Z9jKVxE06BC1"}},{"cell_type":"markdown","source":["#### 9. Part of speech tagging"],"metadata":{"id":"k5UmGsbsOxih"}},{"cell_type":"code","source":["# POS Taging\n","import nltk\n","nltk.download('averaged_perceptron_tagger')\n","\n","text = \"I love reading books.\"\n","\n","# Tokenize the text into words\n","tokens = nltk.word_tokenize(text)\n","\n","# Perform POS tagging\n","pos_tags = nltk.pos_tag(tokens)\n","\n","print(pos_tags)\n"],"metadata":{"id":"btT3ZJBAO6Ik"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 10. Text Vectorization"],"metadata":{"id":"T0VqWOYE6DLQ"}},{"cell_type":"code","source":["# Vectorizing Text"],"metadata":{"id":"yBRtdhth6JDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which text vectorization technique have you used and why?"],"metadata":{"id":"qBMux9mC6MCf"}},{"cell_type":"markdown","source":["Text vectorization is the process of converting textual data into numerical representations, or vectors, that can be processed by machine learning algorithms. It is a crucial step in natural language processing (NLP) tasks as most machine learning models require numerical inputs.\n","\n","There are several techniques for text vectorization. Here are three commonly used approaches:\n","\n","1.Bag-of-Words (BoW):\n","\n","2.TF-IDF (Term Frequency-Inverse Document Frequency):\n","\n","3.Word Embeddings:"],"metadata":{"id":"su2EnbCh6UKQ"}},{"cell_type":"markdown","source":["### 4. Feature Manipulation & Selection"],"metadata":{"id":"-oLEiFgy-5Pf"}},{"cell_type":"markdown","source":["#### 1. Feature Manipulation"],"metadata":{"id":"C74aWNz2AliB"}},{"cell_type":"code","source":["# Manipulate Features to minimize feature correlation and create new features\n","plt.figure(figsize=(20,10))\n","sns.heatmap(df.corr(),annot=True,cmap=\"crest\")\n","plt.show()"],"metadata":{"id":"h1qC4yhBApWC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As we can see there is multicollinearity between the columns 'Temperature' & 'Dew_point_temperature'. Hence we can drop the column 'Dew_point_temperature'."],"metadata":{"id":"gQxsacsGllpO"}},{"cell_type":"code","source":["df.drop('Dew point temperature(°C)', axis=1, inplace=True)"],"metadata":{"id":"52cNK4nKlkv2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creating a new column 'week'"],"metadata":{"id":"X3D6flQllwn3"}},{"cell_type":"markdown","source":["#### 2. Feature Selection"],"metadata":{"id":"2DejudWSA-a0"}},{"cell_type":"code","source":["# Select your features wisely to avoid overfitting"],"metadata":{"id":"YLhe8UmaBCEE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all feature selection methods have you used  and why?"],"metadata":{"id":"pEMng2IbBLp7"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"rb2Lh6Z8BgGs"}},{"cell_type":"markdown","source":["##### Which all features you found important and why?"],"metadata":{"id":"rAdphbQ9Bhjc"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"fGgaEstsBnaf"}},{"cell_type":"markdown","source":["### 5. Data Transformation"],"metadata":{"id":"TNVZ9zx19K6k"}},{"cell_type":"markdown","source":["#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"],"metadata":{"id":"nqoHp30x9hH9"}},{"cell_type":"code","source":["# Transform Your data\n","sns.histplot(df['Rented Bike Count'],kde=True)"],"metadata":{"id":"I6quWQ1T9rtH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Rented Bike Count']=np.sqrt(df['Rented Bike Count'])"],"metadata":{"id":"vneKnTymmGz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Rented Bike Count'].head()"],"metadata":{"id":"ya8wuM1DmHET"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.histplot(df['Rented Bike Count'],kde=True,color='green')"],"metadata":{"id":"uoxeGV35mNQb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Yes, the rented_bike_count column was right skewed. I have to square root transformation as it provides the best normal distribution compared to the log/square tranformations."],"metadata":{"id":"kWgqeCMamTt7"}},{"cell_type":"markdown","source":["### 6. Data Scaling"],"metadata":{"id":"rMDnDkt2B6du"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler"],"metadata":{"id":"Mg0SvCyTmYlD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scaling your data\n","scaler = MinMaxScaler()\n","\n","# fit the scaler to the train set, it will learn the parameters\n","scaler.fit(X_train)\n","\n","# transform train and test sets\n","X_train_scaled = scaler.transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n"],"metadata":{"id":"dL9LWpySC6x_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(df.columns)"],"metadata":{"id":"R98cewbioP1P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","# Create an instance of the MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# Fit the scaler to the training data and transform it\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n","\n","# Transform the test data using the fitted scaler\n","X_train.shape,X_test.shape,y_train.shape,y_test.shape"],"metadata":{"id":"0Cq34tRDoTVH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which method have you used to scale you data and why?"],"metadata":{"id":"yiiVWRdJDDil"}},{"cell_type":"markdown","source":["### 7. Dimesionality Reduction"],"metadata":{"id":"1UUpS68QDMuG"}},{"cell_type":"markdown","source":["##### Do you think that dimensionality reduction is needed? Explain Why?"],"metadata":{"id":"kexQrXU-DjzY"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"GGRlBsSGDtTQ"}},{"cell_type":"code","source":["# DImensionality Reduction (If needed)\n","# Using Pandas get Dummies for Encoding categorical features \n","df=pd.get_dummies(df,drop_first=True,sparse=True)"],"metadata":{"id":"kQfvxBBHDvCa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"id":"m5GPnY8anlE-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"],"metadata":{"id":"T5CmagL3EC8N"}},{"cell_type":"code","source":["# Transform Your data\n","sns.histplot(df['Rented Bike Count'],kde=True)"],"metadata":{"id":"45P9zfnhntjr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Rented Bike Count']=np.sqrt(df['Rented Bike Count'])"],"metadata":{"id":"6vCu-pXynyjr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Rented Bike Count'].head()"],"metadata":{"id":"8WSKjZx2nywy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.histplot(df['Rented Bike Count'],kde=True,color='green')"],"metadata":{"id":"TdHAoe34ny9v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"ZKr75IDuEM7t"}},{"cell_type":"markdown","source":["### 8. Data Splitting"],"metadata":{"id":"BhH2vgX9EjGr"}},{"cell_type":"code","source":["# Split your data to train and test. Choose Splitting ratio wisely.\n","\n","X = df.drop(columns=['Rented Bike Count'],axis=1)\n","y = df['Rented Bike Count']\n"],"metadata":{"id":"0CTyd2UwEyNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train test split our data\n","X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2,random_state=2)"],"metadata":{"id":"JTE4CHCdmsty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape,X_test.shape,y_train.shape,y_test.shape"],"metadata":{"id":"9iEfjZYQms7D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What data splitting ratio have you used and why? "],"metadata":{"id":"qjKvONjwE8ra"}},{"cell_type":"markdown","source":["I have used 80-20 split ratio. This optimal ratio provides enough data for the model to train upon & also to upon."],"metadata":{"id":"Y2lJ8cobFDb_"}},{"cell_type":"markdown","source":["### 9. Handling Imbalanced Dataset"],"metadata":{"id":"P1XJ9OREExlT"}},{"cell_type":"markdown","source":["##### Do you think the dataset is imbalanced? Explain Why."],"metadata":{"id":"VFOzZv6IFROw"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"GeKDIv7pFgcC"}},{"cell_type":"code","source":["# Handling Imbalanced Dataset (If needed)"],"metadata":{"id":"nQsRhhZLFiDs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"],"metadata":{"id":"TIqpNgepFxVj"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"qbet1HwdGDTz"}},{"cell_type":"markdown","source":["## ***7. ML Model Implementation***"],"metadata":{"id":"VfCC591jGiD4"}},{"cell_type":"markdown","source":["### ML Model - 1"],"metadata":{"id":"OB4l2ZhMeS1U"}},{"cell_type":"code","source":["# ML Model - 1 Implementation\n","lr = LinearRegression()\n","\n","# Fit the Algorithm\n","lr.fit(X_train,y_train)\n","\n","# Predict on the model\n","y_pred = lr.predict(X_test)"],"metadata":{"id":"7ebyywQieS1U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import r2_score\n"],"metadata":{"id":"4GV8GSYlppXZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"ArJBuiUVfxKd"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","plt.plot((y_pred)[:80])\n","plt.plot((np.array(y_test)[:80]))\n","plt.legend([\"Predicted\",\"Actual\"])\n","plt.show()"],"metadata":{"id":"rqD5ZohzfxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"4qY1EAkEfxKe"}},{"cell_type":"code","source":["# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","\n","# Fit the Algorithm\n","\n","# Predict on the model"],"metadata":{"id":"Dy61ujd6fxKe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Calculating Performance Metrics for train data\n","\n","# 1. MSE\n","from sklearn.metrics import mean_squared_error\n","\n","# Calculate mean squared error (MSE)\n","MSE = mean_squared_error(y_test, y_pred)\n","print('MSE:', MSE)\n","# 2. RSME\n","RMSE = np.sqrt(MSE)\n","print(\"RMSE :\",RMSE)\n","\n","#3. MAE\n","MAE = mean_absolute_error(y_test, y_pred)\n","print('MAE :', MAE)\n","\n","# R2\n","R2 = r2_score(y_test, y_pred)\n","print('R2 :', R2)\n","\n","# Adjusted R2\n","Adj_R2 = (1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n","print( 'Adjusted R2 :', Adj_R2)"],"metadata":{"id":"4a5wLST-pj1D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"PiV4Ypx8fxKe"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"negyGRa7fxKf"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"TfvqoZmBfxKf"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"OaLui8CcfxKf"}},{"cell_type":"markdown","source":["### ML Model - 2"],"metadata":{"id":"dJ2tPlVmpsJ0"}},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"JWYfwnehpsJ1"}},{"cell_type":"code","source":["# ML Model - 2 Implementation\n","ridge = Ridge()\n","\n","# Fit the Algorithm\n","ridge.fit(X_train,y_train)\n","\n","# Predict on the model\n","y_pred_ridge = ridge.predict(X_test)"],"metadata":{"id":"BYbY3qyTqUJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating Performance Metrics for test data\n","\n","# 1. MSE\n","MSE = mean_squared_error((y_test), (y_pred_ridge))\n","print('MSE :',MSE)\n","\n","# 2. RSME\n","RMSE = np.sqrt(MSE)\n","print(\"RMSE :\",RMSE)\n","\n","#3. MAE\n","MAE = mean_absolute_error((y_test), (y_pred_ridge))\n","print('MAE :', MAE)\n","\n","# R2\n","R2 = r2_score((y_test), (y_pred_ridge))\n","print('R2 :', R2)\n","\n","# Adjusted R2\n","Adj_R2 = (1-(1-r2_score(y_test, y_pred_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n","print( 'Adjusted R2 :', Adj_R2)"],"metadata":{"id":"yEl-hgQWpsJ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","\n","plt.plot((y_pred_ridge)[:80])\n","plt.plot((np.array(y_test)[:80]))\n","plt.legend([\"Predicted\",\"Actual\"])\n","plt.show()"],"metadata":{"id":"BLYSv6YvqdoD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"-jK_YjpMpsJ2"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV"],"metadata":{"id":"o-5cmMBHqkdO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","parameters = {'alpha': [1e-15, 1e-13, 1e-10, 1e-8, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 20, 30, 40, 45, 50, 55, 60, 100]}\n","ridge_gcv = GridSearchCV(ridge, parameters, scoring='r2', cv=5)\n","\n","# Fit the Algorithm\n","ridge_gcv.fit(X_train, y_train)\n","\n","# Predict on the model\n","y_pred_ridge_gcv = ridge_gcv.predict(X_test)"],"metadata":{"id":"Dn0EOfS6psJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating Performance Metrics for test data\n","\n","# 1. MSE\n","MSE = mean_squared_error((y_test), (y_pred_ridge_gcv))\n","print('MSE :',MSE)\n","\n","# 2. RSME\n","RMSE = np.sqrt(MSE)\n","print(\"RMSE :\",RMSE)\n","\n","#3. MAE\n","MAE = mean_absolute_error((y_test), (y_pred_ridge_gcv))\n","print('MAE :', MAE)\n","\n","# R2\n","R2 = r2_score((y_test), (y_pred_ridge_gcv))\n","print('R2 :', R2)\n","\n","# Adjusted R2\n","Adj_R2 = (1-(1-r2_score(y_test, y_pred_ridge_gcv))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n","print( 'Adjusted R2 :', Adj_R2)"],"metadata":{"id":"EvAwBybCr4N1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","\n","plt.plot((y_pred_ridge_gcv)[:80])\n","plt.plot((np.array(y_test)[:80]))\n","plt.legend([\"Predicted\",\"Actual\"])\n","plt.show()"],"metadata":{"id":"jZY80a3Fr4jC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"HAih1iBOpsJ2"}},{"cell_type":"markdown","source":["I have used Grid search CV as hyperparameter optimization technique. It finds the optimal aplha value for which the model is able to perform better"],"metadata":{"id":"9kBgjYcdpsJ2"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"zVGeBEFhpsJ2"}},{"cell_type":"markdown","source":["No significant imporovement seen."],"metadata":{"id":"74yRdG6UpsJ3"}},{"cell_type":"markdown","source":["#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."],"metadata":{"id":"bmKjuQ-FpsJ3"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"BDKtOrBQpsJ3"}},{"cell_type":"markdown","source":["### ML Model - 3"],"metadata":{"id":"Fze-IPXLpx6K"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor"],"metadata":{"id":"wbkc-u83sDl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ML Model - 3 Implementation\n","rf_model = RandomForestRegressor()\n","\n","# Fit the Algorithm\n","rf_model.fit(X_train, y_train)\n","\n","# Predict on the model\n","y_pred_rf = rf_model.predict(X_test)"],"metadata":{"id":"FFrSXAtrpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"7AN1z2sKpx6M"}},{"cell_type":"code","source":["# Calculating Performance Metrics for test data\n","\n","# 1. MSE\n","MSE = mean_squared_error((y_test), (y_pred_rf))\n","print('MSE :',MSE)\n","\n","# 2. RSME\n","RMSE = np.sqrt(MSE)\n","print(\"RMSE :\",RMSE)\n","\n","#3. MAE\n","MAE = mean_absolute_error((y_test), (y_pred_rf))\n","print('MAE :', MAE)\n","\n","# R2\n","R2 = r2_score((y_test), (y_pred_rf))\n","print('R2 :', R2)\n","\n","# Adjusted R2\n","Adj_R2 = (1-(1-r2_score(y_test, y_pred_rf))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))\n","print( 'Adjusted R2 :', Adj_R2)\n"],"metadata":{"id":"xIY4lxxGpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","plt.plot((y_pred_rf)[:80])\n","plt.plot((np.array(y_test)[:80]))\n","plt.legend([\"Predicted\",\"Actual\"])\n","plt.show()"],"metadata":{"id":"ofUtSYUNxqUM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"9PIHJqyupx6M"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV"],"metadata":{"id":"wRvlpCjqy2cz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","param_grid = {'n_estimators':[5, 10, 15, 20, 30],\n","              'max_depth' : [3, 5, 10, 15, 20],\n","              'max_features':['auto','sqrt','log2']\n","              }\n","Random_forest_Grid_search = GridSearchCV(RandomForestRegressor(),param_grid=param_grid,n_jobs=-1,cv=3)\n","\n","# Fit the Algorithm\n","Random_forest_Grid_search.fit(X_train, y_train)\n","\n","# Predict on the model\n","y_pred_rf_gcv = Random_forest_Grid_search.predict(X_test)"],"metadata":{"id":"eSVXuaSKpx6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"_-qAgymDpx6N"}},{"cell_type":"markdown","source":["I have used Grid search CV as hyperparameter optimization technique. It finds the optimal aplha value for which the model is able to perform better"],"metadata":{"id":"lQMffxkwpx6N"}},{"cell_type":"markdown","source":["##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."],"metadata":{"id":"Z-hykwinpx6N"}},{"cell_type":"markdown","source":["Major improvements compared to linear models were seen, however the hyperparamter max depth performs better @ None i.e till all the leaf nodes are pure."],"metadata":{"id":"MzVzZC6opx6N"}},{"cell_type":"markdown","source":["### 1. Which Evaluation metrics did you consider for a positive business impact and why?"],"metadata":{"id":"h_CCil-SKHpo"}},{"cell_type":"markdown","source":["I have chosen Adjusted R2 score as it is best able to explain the variance in the data. The adjusted R2 score also adjusts for predictors that are not significant in a regression model."],"metadata":{"id":"jHVz9hHDKFms"}},{"cell_type":"markdown","source":["### 2. Which ML model did you choose from the above created models as your final prediction model and why?"],"metadata":{"id":"cBFFvTBNJzUa"}},{"cell_type":"markdown","source":["I have chosen Random Forest Regressor as my final prediction model. With an adjusted r2 score of 91%, we can consider random forest regressor as our best model."],"metadata":{"id":"6ksF5Q1LKTVm"}},{"cell_type":"markdown","source":["### 3. Explain the model which you have used and the feature importance using any model explainability tool?"],"metadata":{"id":"HvGl1hHyA_VK"}},{"cell_type":"code","source":["features = X_train.columns\n","importances = rf_model.feature_importances_\n","indices = np.argsort(importances)"],"metadata":{"id":"UJ-sDinszOIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(15, 15))\n","plt.style.use('dark_background')\n","plt.title('Feature Importance')\n","plt.barh(range(len(indices)), importances[indices], color='aqua', align='center')\n","plt.yticks(range(len(indices)), [features[i] for i in indices])\n","plt.xlabel('Relative Importance')\n","\n","plt.show()\n"],"metadata":{"id":"5aLxNmVkzU82"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As we can see from the feature importance graph, the feature 'temperature' can be considered as most important with relative importance of 0.30. The next 2 features are humidity and functioning day-yes can be considered with relative importance of 0.17. As these 3 main features play a role in decreasing the value of entropy, the machine learning model, random forest regressor considers them closer to the root node."],"metadata":{"id":"mgB9ZiACzYtW"}},{"cell_type":"markdown","source":["## ***8.*** ***Future Work (Optional)***"],"metadata":{"id":"EyNgTHvd2WFk"}},{"cell_type":"markdown","source":["### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"],"metadata":{"id":"KH5McJBi2d8v"}},{"cell_type":"code","source":["# Save the File"],"metadata":{"id":"bQIANRl32f4J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"],"metadata":{"id":"iW_Lq9qf2h6X"}},{"cell_type":"code","source":["# Load the File and predict unseen data."],"metadata":{"id":"oEXk9ydD2nVC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"],"metadata":{"id":"-Kee-DAl2viO"}},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["In our analysis, we initially did EDA on all the features of our datset. We first analysed our dependent variable i.e, 'Rented Bike Count' and also transformed it. Next we analysed categorical variable and dropped the variable who had majority of one class. we also analysed numerical variable, check out the correlation, distribution and their relationship with the dependent variable. We then later hot encoded the categorical variables.\n","\n","\n","Next we implemented 4 machine learning algorithms Linear Regression,Ridge(L2), Lasso(L1), Random Forest Regressor. We did some hyperparameter tuning to improve our model performance.\n","\n","\n","*   Out of all above models Random forest Regressor gives the highest R2 score of 91% for test Set.\n","*   No overfitting is seen.\n","\n","***So the bike rental company can deploy a machine learning model that uses Random Forest Regressor to predict the demand for city bikes for a particular hour, which can help the company meet the demand accurately. On the contrary when the company predicts to be a low demand day/season, the bikes can be sent to maintainance.***"],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}